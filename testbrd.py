#https://blog.finxter.com/fixed-modulenotfounderror-no-module-named-tiktoken/
# pip install tiktoken

#https://pypi.org/project/tiktoken/
# üí° If you have Windows and you have set up the py alias
# py -m pip install tiktoken

import tiktoken


string = """Lo que subyace al racismo algor√≠tmico
Entre las causas apuntadas para tales situaciones, est√°n:

Datos de entrenamiento sesgados: los algoritmos de IA aprenden a partir de datos hist√≥ricos. Si estos datos reflejan desigualdades raciales o no representan adecuadamente la diversidad de la poblaci√≥n, el algoritmo puede aprender y reproducir estos sesgos. Un estudio de 2019 mostr√≥ que los sistemas de reconocimiento facial ten√≠an tasas de error m√°s altas para personas de piel oscura, especialmente mujeres negras, debido a la falta de representaci√≥n en los conjuntos de datos de entrenamiento.
Dise√±o algor√≠tmico: la inteligencia artificial no es magia. Quienes dise√±an y desarrollan los algoritmos y sistemas de IA pueden, con o sin intencionalidad, incorporar sus propios prejuicios en la creaci√≥n de algoritmos. Las decisiones sobre cu√°les variables incluir, c√≥mo ponderarlas y de qu√© manera interpretarlas pueden influir en los resultados finales.
Interpretaci√≥n y uso de resultados: incluso si un algoritmo es t√©cnicamente imparcial, la forma en que se utilizan sus resultados puede conducir a pr√°cticas discriminatorias.
La investigaci√≥n de Tarc√≠zio Silva aborda el impacto del racismo algor√≠tmico en la visi√≥n computacional, destacando c√≥mo los sistemas de inteligencia artificial (IA) y aprendizaje autom√°tico pueden perpetuar y amplificar prejuicios raciales a trav√©s de sus mecanismos de reconocimiento y clasificaci√≥n de im√°genes. Silva examina la construcci√≥n y expresi√≥n del racismo en la infraestructura online y las interfaces digitales, argumentando que tanto los algoritmos (el ‚Äúback end‚Äù) como las representaciones visuales y textuales (el ‚Äúfront end‚Äù) son materializan estereotipos invisibles que afectan a grupos racializados.

A trav√©s de un an√°lisis fundamentado en la Teor√≠a Racial Cr√≠tica y estudios sobre la blanquitud, Silva propone un marco para comprender y desmantelar la opresi√≥n algor√≠tmica, subrayando la necesidad de abrir las ‚Äúcajas negras‚Äù de la tecnolog√≠a para revelar y confrontar los sesgos raciales inherentes en los sistemas de visi√≥n computacional. Su trabajo resalta la importancia de abordar tanto los aspectos t√©cnicos como los culturales y sociales en la lucha contra el racismo algor√≠tmico, instando a una mayor diversidad e inclusi√≥n en los campos de la ciencia y la tecnolog√≠a. 

El racismo algor√≠tmico es un desaf√≠o significativo en la era de la IA. Es crucial que las personas en roles de desarrollo, investigaci√≥n e, incluso, las usuarias sean conscientes de estos sesgos y trabajen activamente para crear algoritmos m√°s inclusivos y equitativos. Esto implica diversificar los conjuntos de datos, y tambi√©n cuestionar y revisar constantemente los supuestos subyacentes en el desarrollo de tecnolog√≠as. El fiasco de Google Gemini, por citar un ejemplo reciente, nos ense√±a que no se trata de corregir el racismo con m√°s racismo, sino de desarrollar colectivamente algoritmos igualitarios.

La lucha contra el racismo algor√≠tmico y la creaci√≥n de tecnolog√≠as m√°s equitativas se basa en un principio clave: aprender y ense√±ar c√≥mo funcionan realmente los sistemas tecnol√≥gicos por dentro. Comprender el funcionamiento interno de los algoritmos y los sistemas de IA es esencial para identificar y corregir los sesgos y prejuicios que estos pueden perpetuar. Esto requiere un enfoque educativo y formativo que no solo se centre en las habilidades t√©cnicas ‚Äînecesarias para desarrollar y programar software‚Äî sino tambi√©n en la sensibilizaci√≥n respecto de los impactos sociales y culturales de la tecnolog√≠a. En este sentido, la educaci√≥n en tecnolog√≠a debe incluir un curr√≠culo que aborde la √©tica en IA, la justicia social y los estudios sobre el racismo y la discriminaci√≥n, proporcionando a los estudiantes las herramientas para construir sistemas m√°s justos y representativos.

Desde Latinoam√©rica y entre los grupos minoritarios, la creaci√≥n de capacidades en tecnolog√≠a es especialmente crucial para desafiar y cambiar las narrativas dominantes en el campo de la IA. Al empoderar a estos grupos para que participen activamente en el desarrollo tecnol√≥gico, se abre la puerta a una diversidad de perspectivas y experiencias que pueden informar y enriquecer el proceso de dise√±o de algoritmos.

Fomentar la inclusi√≥n de voces marginadas en la ciencia y la tecnolog√≠a contribuye a reducir los estereotipos raciales y sesgos en los sistemas de IA, y promueve la creaci√≥n de soluciones innovadoras que atienden a las necesidades y desaf√≠os de todas las personas. Por √∫ltimo, construir una comunidad tecnol√≥gica inclusiva y diversa, en nuestra regi√≥n y m√°s all√°, es un paso fundamental hacia la eliminaci√≥n de estereotipos raciales y la creaci√≥n de algoritmos que sirvan equitativamente a toda la sociedad.

Solo as√≠ podremos asegurar que la IA sea un aporte al desarrollo."""


enc = tiktoken.encoding_for_model("gpt-4")
result = enc.encode(string)
print(len(result))

#https://saurabhjadhavblogs.com/installing-langchain-how-to-install-langchain-and-get-started-with-it
#https://python.langchain.com/docs/get_started/quickstart/